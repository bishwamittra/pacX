{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "minimum iterations: 2 max iterations: 2\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   accuracy blackbox dataset explainer  \\\n0  0.545455       nn     zoo     sygus   \n1  1.000000       nn     zoo     sygus   \n\n                                         explanation  explanation size  \\\n0       (and (not fins) (and tail (< legs (/ 3 4))))               3.0   \n1   (and hair milk airborne toothed backbone brea...              16.0   \n\n   positive counterexamples  \\\n0                  0.142857   \n1                  0.333333   \n\n                                               query  random words checked  \\\n0  - threshold: 0.1\\n- specific_input: [1.0, 0.0,...                3329.0   \n1  - threshold: 0.1\\n- specific_input: [1.0, 0.0,...                  89.0   \n\n   syntactic grammar  terminate       time  time learner  time verifier  \\\n0                1.0        0.0  11.534405      9.811970       0.717693   \n1                0.0        1.0   0.049068      0.022897       0.025799   \n\n   total counterexamples  \n0                   21.0  \n1                    3.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>accuracy</th>\n      <th>blackbox</th>\n      <th>dataset</th>\n      <th>explainer</th>\n      <th>explanation</th>\n      <th>explanation size</th>\n      <th>positive counterexamples</th>\n      <th>query</th>\n      <th>random words checked</th>\n      <th>syntactic grammar</th>\n      <th>terminate</th>\n      <th>time</th>\n      <th>time learner</th>\n      <th>time verifier</th>\n      <th>total counterexamples</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.545455</td>\n      <td>nn</td>\n      <td>zoo</td>\n      <td>sygus</td>\n      <td>(and (not fins) (and tail (&lt; legs (/ 3 4))))</td>\n      <td>3.0</td>\n      <td>0.142857</td>\n      <td>- threshold: 0.1\\n- specific_input: [1.0, 0.0,...</td>\n      <td>3329.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>11.534405</td>\n      <td>9.811970</td>\n      <td>0.717693</td>\n      <td>21.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.000000</td>\n      <td>nn</td>\n      <td>zoo</td>\n      <td>sygus</td>\n      <td>(and hair milk airborne toothed backbone brea...</td>\n      <td>16.0</td>\n      <td>0.333333</td>\n      <td>- threshold: 0.1\\n- specific_input: [1.0, 0.0,...</td>\n      <td>89.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.049068</td>\n      <td>0.022897</td>\n      <td>0.025799</td>\n      <td>3.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "select_blackbox = ['dt', 'nn', 'rf'][1]\n",
    "\n",
    "df = pd.read_csv(\"data/output/result.csv\", header=None)\n",
    "df.columns = ['accuracy', 'blackbox', 'dataset', 'explainer', 'explanation', 'explanation size', 'positive counterexamples', 'query', 'random words checked', 'syntactic grammar', 'terminate', 'time', 'time learner', 'time verifier', 'total counterexamples']\n",
    "df = df[df['blackbox'] == select_blackbox]\n",
    "print(\"minimum iterations:\", min(df.groupby(['query'])['explanation'].count()), \"max iterations:\",max(df.groupby(['query'])['explanation'].count()))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "  dataset explainer                                              query  \\\n0     zoo     sygus  - threshold: 0.1\\n- specific_input: [1.0, 0.0,...   \n1     zoo     sygus  - threshold: 0.1\\n- specific_input: [1.0, 0.0,...   \n\n   syntactic grammar  accuracy  explanation size  positive counterexamples  \\\n0                0.0  1.000000              16.0                  0.333333   \n1                1.0  0.545455               3.0                  0.142857   \n\n   random words checked  terminate       time  time learner  time verifier  \\\n0                  89.0        1.0   0.049068      0.022897       0.025799   \n1                3329.0        0.0  11.534405      9.811970       0.717693   \n\n   total counterexamples  \n0                    3.0  \n1                   21.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>explainer</th>\n      <th>query</th>\n      <th>syntactic grammar</th>\n      <th>accuracy</th>\n      <th>explanation size</th>\n      <th>positive counterexamples</th>\n      <th>random words checked</th>\n      <th>terminate</th>\n      <th>time</th>\n      <th>time learner</th>\n      <th>time verifier</th>\n      <th>total counterexamples</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>zoo</td>\n      <td>sygus</td>\n      <td>- threshold: 0.1\\n- specific_input: [1.0, 0.0,...</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>16.0</td>\n      <td>0.333333</td>\n      <td>89.0</td>\n      <td>1.0</td>\n      <td>0.049068</td>\n      <td>0.022897</td>\n      <td>0.025799</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>zoo</td>\n      <td>sygus</td>\n      <td>- threshold: 0.1\\n- specific_input: [1.0, 0.0,...</td>\n      <td>1.0</td>\n      <td>0.545455</td>\n      <td>3.0</td>\n      <td>0.142857</td>\n      <td>3329.0</td>\n      <td>0.0</td>\n      <td>11.534405</td>\n      <td>9.811970</td>\n      <td>0.717693</td>\n      <td>21.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# take median\n",
    "group_list = ['dataset','explainer','query', 'syntactic grammar']\n",
    "df_med = df.groupby(group_list).median()\n",
    "df_med.reset_index(inplace=True)\n",
    "df_med"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# find representative explanation\n",
    "query_explanations = {}\n",
    "for key, item in df.groupby(['dataset','explainer','query', 'syntactic grammar'], as_index = False):\n",
    "    item.reset_index(inplace=True, drop=True)\n",
    "    if(len(item) == 1):\n",
    "        query_explanations[key] = item['explanation'].item()\n",
    "    else:\n",
    "        # nearest explanation to the average accuracy\n",
    "        explanation = item.iloc[item.index[(item['accuracy']-df_med['accuracy'][(df_med['dataset'] == key[0]) & (df_med['explainer'] == key[1]) & (df_med['syntactic grammar'] == key[3]) & (df_med['query'] == key[2])].item()).abs().argsort()][0]]['explanation']\n",
    "        query_explanations[key] = explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "  dataset  syntactic grammar explainer  \\\n0     zoo                0.0     sygus   \n1     zoo                1.0     sygus   \n\n                                               query  \\\n0  - threshold: 0.1\\n- specific_input: [1.0, 0.0,...   \n1  - threshold: 0.1\\n- specific_input: [1.0, 0.0,...   \n\n                                     explanation  accuracy   time  \\\n0   (and (not fins) (and tail (< legs (/ 3 4))))      1.00   0.05   \n1   (and (not fins) (and tail (< legs (/ 3 4))))      0.55  11.53   \n\n   time learner  time verifier  random words checked  total counterexamples  \\\n0          0.02           0.03                  89.0                    3.0   \n1          9.81           0.72                3329.0                   21.0   \n\n   positive counterexamples  \n0                      0.33  \n1                      0.14  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>syntactic grammar</th>\n      <th>explainer</th>\n      <th>query</th>\n      <th>explanation</th>\n      <th>accuracy</th>\n      <th>time</th>\n      <th>time learner</th>\n      <th>time verifier</th>\n      <th>random words checked</th>\n      <th>total counterexamples</th>\n      <th>positive counterexamples</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>zoo</td>\n      <td>0.0</td>\n      <td>sygus</td>\n      <td>- threshold: 0.1\\n- specific_input: [1.0, 0.0,...</td>\n      <td>(and (not fins) (and tail (&lt; legs (/ 3 4))))</td>\n      <td>1.00</td>\n      <td>0.05</td>\n      <td>0.02</td>\n      <td>0.03</td>\n      <td>89.0</td>\n      <td>3.0</td>\n      <td>0.33</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>zoo</td>\n      <td>1.0</td>\n      <td>sygus</td>\n      <td>- threshold: 0.1\\n- specific_input: [1.0, 0.0,...</td>\n      <td>(and (not fins) (and tail (&lt; legs (/ 3 4))))</td>\n      <td>0.55</td>\n      <td>11.53</td>\n      <td>9.81</td>\n      <td>0.72</td>\n      <td>3329.0</td>\n      <td>21.0</td>\n      <td>0.14</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "df_output = df_med\n",
    "df_output = df_output.drop(\"terminate\", axis=1)\n",
    "df_output['explanation'] = np.nan \n",
    "for key in query_explanations:\n",
    "    df_output['explanation'][(df_output['dataset'] == key[0]) & (df_output['explainer'] == key[1]) & (df_output['query'] == key[2])] = query_explanations[key]\n",
    "\n",
    "# reorganise columns\n",
    "df_output = df_output[[ 'dataset',  'syntactic grammar', 'explainer','query', 'explanation', 'accuracy', 'time', 'time learner', 'time verifier', 'random words checked', 'total counterexamples', 'positive counterexamples']]\n",
    "df_output = df_output.round(2)\n",
    "df_output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n\n\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "### Query"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "zoo\n- threshold: 0.1\n- specific_input: [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.25, 1.0, 0.0, 0.0]\n- detailed_input: [('hair', 1.0), ('feathers', 0.0), ('eggs', 0.0), ('milk', 1.0), ('airborne', 1.0), ('aquatic', 0.0), ('predator', 0.0), ('toothed', 1.0), ('backbone', 1.0), ('breathes', 1.0), ('venomous', 0.0), ('fins', 0.0), ('legs', 0.25), ('tail', 1.0), ('domestic', 0.0), ('catsize', 0.0)]\nsygus\n0.0\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "### Result"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(and (not fins) (and tail (< legs (/ 3 4))))\n\n\naccuracy 1.0\n\n\n\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "### Query"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "zoo\n- threshold: 0.1\n- specific_input: [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.25, 1.0, 0.0, 0.0]\n- detailed_input: [('hair', 1.0), ('feathers', 0.0), ('eggs', 0.0), ('milk', 1.0), ('airborne', 1.0), ('aquatic', 0.0), ('predator', 0.0), ('toothed', 1.0), ('backbone', 1.0), ('breathes', 1.0), ('venomous', 0.0), ('fins', 0.0), ('legs', 0.25), ('tail', 1.0), ('domestic', 0.0), ('catsize', 0.0)]\nsygus\n1.0\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "### Result"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(and (not fins) (and tail (< legs (/ 3 4))))\n\n\naccuracy 0.55\n"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from IPython.display import Markdown, display\n",
    "from trustable_explanation import helper_functions\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "features = ['hair', 'feathers', 'eggs', 'milk', 'airborne', 'aquatic', 'predator', 'toothed', 'backbone', 'breathes', 'venomous', 'fins', 'legs', 'tail', 'domestic', 'catsize']\n",
    "# print results in an explainable manner\n",
    "for key, item in df_output.groupby(['dataset','query','explainer','syntactic grammar'], as_index = False):\n",
    "    print(\"\\n\\n\")\n",
    "    display(Markdown(\"### Query\"))\n",
    "    for i in key:\n",
    "        print(i)\n",
    "    display(Markdown(\"### Result\"))\n",
    "    if(key[1] == \"logistic regression\"):\n",
    "        feature_importance = np.fromstring(item['explanation'].item()[1:-1], dtype=np.float, sep=' ')\n",
    "        feature_importance = 100.0 * (feature_importance / (abs(feature_importance).max()))\n",
    "        sorted_idx = np.argsort(abs(feature_importance))\n",
    "        pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "        featfig = plt.figure()\n",
    "        featax = featfig.add_subplot(1, 1, 1)\n",
    "        featax.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "        featax.set_yticks(pos)\n",
    "        featax.set_yticklabels(np.array(features)[sorted_idx])\n",
    "        featax.set_xlabel('Relative Feature Importance')\n",
    "        plt.tight_layout()   \n",
    "        plt.show()\n",
    "    elif(key[1] == \"decision tree\"):\n",
    "        dt = None\n",
    "        with open(item['explanation'].item(), 'rb') as fid:\n",
    "            dt = pickle.load(fid)\n",
    "        print(helper_functions.tree_to_code(dt,features))\n",
    "    else:\n",
    "        print(item['explanation'].item())\n",
    "    print(\"\\n\\naccuracy\",item['accuracy'].item())\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to remote \n",
    "# df_output.to_csv(\"data/output/summary.csv\", index = False)\n",
    "df_output.to_csv(\"/home/bishwamittra/Dropbox/trustable_explanations/result.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}