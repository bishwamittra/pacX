{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "minimum iterations: 47 max iterations: 100\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   accuracy       blackbox dataset explainer                 explanation  \\\n0       1.0  decision tree     zoo     sygus   (and (not breathes) fins)   \n1       1.0  decision tree     zoo     sygus   (and (not breathes) fins)   \n2       1.0  decision tree     zoo     sygus   (and (not breathes) fins)   \n3       1.0  decision tree     zoo     sygus   (and (not breathes) fins)   \n4       1.0  decision tree     zoo     sygus   (and (not breathes) fins)   \n\n   explanation size  positive counterexamples query  random words checked  \\\n0               2.0                  0.500000  true                 962.0   \n1               2.0                  0.428571  true                 964.0   \n2               2.0                  0.333333  true                1030.0   \n3               2.0                  0.333333  true                 969.0   \n4               2.0                  0.250000  true                 827.0   \n\n   syntactic grammar  terminate      time  time learner  time verifier  \\\n0                1.0        1.0  0.990528      0.334000       0.655108   \n1                1.0        1.0  0.987706      0.325856       0.660411   \n2                1.0        1.0  1.183521      0.432247       0.749661   \n3                1.0        1.0  1.020707      0.392725       0.626534   \n4                1.0        1.0  0.630564      0.246163       0.383300   \n\n   total counterexamples  \n0                    6.0  \n1                    7.0  \n2                    9.0  \n3                    9.0  \n4                    8.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>accuracy</th>\n      <th>blackbox</th>\n      <th>dataset</th>\n      <th>explainer</th>\n      <th>explanation</th>\n      <th>explanation size</th>\n      <th>positive counterexamples</th>\n      <th>query</th>\n      <th>random words checked</th>\n      <th>syntactic grammar</th>\n      <th>terminate</th>\n      <th>time</th>\n      <th>time learner</th>\n      <th>time verifier</th>\n      <th>total counterexamples</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>decision tree</td>\n      <td>zoo</td>\n      <td>sygus</td>\n      <td>(and (not breathes) fins)</td>\n      <td>2.0</td>\n      <td>0.500000</td>\n      <td>true</td>\n      <td>962.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.990528</td>\n      <td>0.334000</td>\n      <td>0.655108</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>decision tree</td>\n      <td>zoo</td>\n      <td>sygus</td>\n      <td>(and (not breathes) fins)</td>\n      <td>2.0</td>\n      <td>0.428571</td>\n      <td>true</td>\n      <td>964.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.987706</td>\n      <td>0.325856</td>\n      <td>0.660411</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>decision tree</td>\n      <td>zoo</td>\n      <td>sygus</td>\n      <td>(and (not breathes) fins)</td>\n      <td>2.0</td>\n      <td>0.333333</td>\n      <td>true</td>\n      <td>1030.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.183521</td>\n      <td>0.432247</td>\n      <td>0.749661</td>\n      <td>9.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>decision tree</td>\n      <td>zoo</td>\n      <td>sygus</td>\n      <td>(and (not breathes) fins)</td>\n      <td>2.0</td>\n      <td>0.333333</td>\n      <td>true</td>\n      <td>969.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.020707</td>\n      <td>0.392725</td>\n      <td>0.626534</td>\n      <td>9.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.0</td>\n      <td>decision tree</td>\n      <td>zoo</td>\n      <td>sygus</td>\n      <td>(and (not breathes) fins)</td>\n      <td>2.0</td>\n      <td>0.250000</td>\n      <td>true</td>\n      <td>827.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.630564</td>\n      <td>0.246163</td>\n      <td>0.383300</td>\n      <td>8.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "select_blackbox = ['dt', 'nn', 'rf'][1]\n",
    "sanity = True\n",
    "if(sanity):\n",
    "    df = pd.read_csv(\"data/output/sanity_result.csv\", header=None)\n",
    "    df.columns = ['accuracy', 'blackbox', 'dataset', 'explainer', 'explanation', 'explanation size', 'positive counterexamples', 'query', 'random words checked', 'syntactic grammar', 'terminate', 'time', 'time learner', 'time verifier', 'total counterexamples']\n",
    "    df['query'].fillna('true', inplace=True)\n",
    "\n",
    "else:\n",
    "    df = pd.read_csv(\"data/output/result.csv\", header=None)\n",
    "    df.columns = ['accuracy', 'blackbox', 'dataset', 'explainer', 'explanation', 'explanation size', 'positive counterexamples', 'query', 'random words checked', 'syntactic grammar', 'terminate', 'time', 'time learner', 'time verifier', 'total counterexamples']\n",
    "    df = df[df['blackbox'] == select_blackbox]\n",
    "\n",
    "\n",
    "print(\"minimum iterations:\", min(df.groupby(['query'])['explanation'].count()), \"max iterations:\",max(df.groupby(['query'])['explanation'].count()))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "  dataset explainer         query  syntactic grammar  accuracy  \\\n0     zoo     sygus  breathes = 0                1.0  0.890909   \n1     zoo     sygus  breathes = 1                1.0  0.977273   \n2     zoo     sygus      fins = 0                1.0  0.986532   \n3     zoo     sygus      milk = 1                1.0  1.000000   \n4     zoo     sygus          true                1.0  1.000000   \n\n   explanation size  positive counterexamples  random words checked  \\\n0              0.77                  0.017951                603.23   \n1              0.68                  0.016543                584.09   \n2              0.72                  0.014220                588.73   \n3              0.70                  0.013073                588.46   \n4              2.00                  0.054862                722.42   \n\n   terminate      time  time learner  time verifier  total counterexamples  \n0        1.0  0.172746      0.066136       0.106296                  27.79  \n1        1.0  0.151084      0.057888       0.092929                  24.49  \n2        1.0  0.157305      0.059228       0.097778                  30.34  \n3        1.0  0.164348      0.065890       0.098176                  21.90  \n4        1.0  0.563055      0.302349       0.259896                  52.14  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>explainer</th>\n      <th>query</th>\n      <th>syntactic grammar</th>\n      <th>accuracy</th>\n      <th>explanation size</th>\n      <th>positive counterexamples</th>\n      <th>random words checked</th>\n      <th>terminate</th>\n      <th>time</th>\n      <th>time learner</th>\n      <th>time verifier</th>\n      <th>total counterexamples</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>zoo</td>\n      <td>sygus</td>\n      <td>breathes = 0</td>\n      <td>1.0</td>\n      <td>0.890909</td>\n      <td>0.77</td>\n      <td>0.017951</td>\n      <td>603.23</td>\n      <td>1.0</td>\n      <td>0.172746</td>\n      <td>0.066136</td>\n      <td>0.106296</td>\n      <td>27.79</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>zoo</td>\n      <td>sygus</td>\n      <td>breathes = 1</td>\n      <td>1.0</td>\n      <td>0.977273</td>\n      <td>0.68</td>\n      <td>0.016543</td>\n      <td>584.09</td>\n      <td>1.0</td>\n      <td>0.151084</td>\n      <td>0.057888</td>\n      <td>0.092929</td>\n      <td>24.49</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>zoo</td>\n      <td>sygus</td>\n      <td>fins = 0</td>\n      <td>1.0</td>\n      <td>0.986532</td>\n      <td>0.72</td>\n      <td>0.014220</td>\n      <td>588.73</td>\n      <td>1.0</td>\n      <td>0.157305</td>\n      <td>0.059228</td>\n      <td>0.097778</td>\n      <td>30.34</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>zoo</td>\n      <td>sygus</td>\n      <td>milk = 1</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>0.70</td>\n      <td>0.013073</td>\n      <td>588.46</td>\n      <td>1.0</td>\n      <td>0.164348</td>\n      <td>0.065890</td>\n      <td>0.098176</td>\n      <td>21.90</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>zoo</td>\n      <td>sygus</td>\n      <td>true</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>2.00</td>\n      <td>0.054862</td>\n      <td>722.42</td>\n      <td>1.0</td>\n      <td>0.563055</td>\n      <td>0.302349</td>\n      <td>0.259896</td>\n      <td>52.14</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "# take median\n",
    "group_list = ['dataset','explainer','query', 'syntactic grammar']\n",
    "df_med = df.groupby(group_list).mean()\n",
    "df_med.reset_index(inplace=True)\n",
    "df_med"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# find representative explanation\n",
    "query_explanations = {}\n",
    "for key, item in df.groupby(['dataset','explainer','query', 'syntactic grammar'], as_index = False):\n",
    "    item.reset_index(inplace=True, drop=True)\n",
    "    if(len(item) == 1):\n",
    "        query_explanations[key] = item['explanation'].item()\n",
    "    else:\n",
    "        # nearest explanation to the average accuracy\n",
    "        explanation = item.iloc[item.index[(item['accuracy']-df_med['accuracy'][(df_med['dataset'] == key[0]) & (df_med['explainer'] == key[1]) & (df_med['syntactic grammar'] == key[3]) & (df_med['query'] == key[2])].item()).abs().argsort()][0]]['explanation']\n",
    "        query_explanations[key] = explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "  dataset  syntactic grammar explainer         query  \\\n0     zoo                1.0     sygus  breathes = 0   \n1     zoo                1.0     sygus  breathes = 1   \n2     zoo                1.0     sygus      fins = 0   \n3     zoo                1.0     sygus      milk = 1   \n4     zoo                1.0     sygus          true   \n\n                  explanation  accuracy  time  time learner  time verifier  \\\n0                         NaN      0.89  0.17          0.07           0.11   \n1                       false      0.98  0.15          0.06           0.09   \n2                         NaN      0.99  0.16          0.06           0.10   \n3                         NaN      1.00  0.16          0.07           0.10   \n4   (and (not breathes) fins)      1.00  0.56          0.30           0.26   \n\n   random words checked  total counterexamples  positive counterexamples  \\\n0                603.23                  27.79                      0.02   \n1                584.09                  24.49                      0.02   \n2                588.73                  30.34                      0.01   \n3                588.46                  21.90                      0.01   \n4                722.42                  52.14                      0.05   \n\n   explanation size  \n0              0.77  \n1              0.68  \n2              0.72  \n3              0.70  \n4              2.00  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>syntactic grammar</th>\n      <th>explainer</th>\n      <th>query</th>\n      <th>explanation</th>\n      <th>accuracy</th>\n      <th>time</th>\n      <th>time learner</th>\n      <th>time verifier</th>\n      <th>random words checked</th>\n      <th>total counterexamples</th>\n      <th>positive counterexamples</th>\n      <th>explanation size</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>zoo</td>\n      <td>1.0</td>\n      <td>sygus</td>\n      <td>breathes = 0</td>\n      <td>NaN</td>\n      <td>0.89</td>\n      <td>0.17</td>\n      <td>0.07</td>\n      <td>0.11</td>\n      <td>603.23</td>\n      <td>27.79</td>\n      <td>0.02</td>\n      <td>0.77</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>zoo</td>\n      <td>1.0</td>\n      <td>sygus</td>\n      <td>breathes = 1</td>\n      <td>false</td>\n      <td>0.98</td>\n      <td>0.15</td>\n      <td>0.06</td>\n      <td>0.09</td>\n      <td>584.09</td>\n      <td>24.49</td>\n      <td>0.02</td>\n      <td>0.68</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>zoo</td>\n      <td>1.0</td>\n      <td>sygus</td>\n      <td>fins = 0</td>\n      <td>NaN</td>\n      <td>0.99</td>\n      <td>0.16</td>\n      <td>0.06</td>\n      <td>0.10</td>\n      <td>588.73</td>\n      <td>30.34</td>\n      <td>0.01</td>\n      <td>0.72</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>zoo</td>\n      <td>1.0</td>\n      <td>sygus</td>\n      <td>milk = 1</td>\n      <td>NaN</td>\n      <td>1.00</td>\n      <td>0.16</td>\n      <td>0.07</td>\n      <td>0.10</td>\n      <td>588.46</td>\n      <td>21.90</td>\n      <td>0.01</td>\n      <td>0.70</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>zoo</td>\n      <td>1.0</td>\n      <td>sygus</td>\n      <td>true</td>\n      <td>(and (not breathes) fins)</td>\n      <td>1.00</td>\n      <td>0.56</td>\n      <td>0.30</td>\n      <td>0.26</td>\n      <td>722.42</td>\n      <td>52.14</td>\n      <td>0.05</td>\n      <td>2.00</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "df_output = df_med\n",
    "df_output = df_output.drop(\"terminate\", axis=1)\n",
    "df_output['explanation'] = np.nan \n",
    "for key in query_explanations:\n",
    "    df_output['explanation'][(df_output['dataset'] == key[0]) & (df_output['explainer'] == key[1]) & (df_output['syntactic grammar'] == key[3]) & (df_output['query'] == key[2])] = query_explanations[key]\n",
    "\n",
    "# reorganise columns\n",
    "df_output = df_output[[ 'dataset',  'syntactic grammar', 'explainer','query', 'explanation', 'accuracy', 'time', 'time learner', 'time verifier', 'random words checked', 'total counterexamples', 'positive counterexamples', 'explanation size']]\n",
    "df_output = df_output.round(2)\n",
    "df_output.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n\n\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "### Query"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "zoo\nbreathes = 0\nsygus\n1.0\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "### Result"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "nan\n\n\naccuracy 0.89\n\n\n\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "### Query"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "zoo\nbreathes = 1\nsygus\n1.0\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "### Result"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "false\n\n\naccuracy 0.98\n\n\n\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "### Query"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "zoo\nfins = 0\nsygus\n1.0\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "### Result"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "nan\n\n\naccuracy 0.99\n\n\n\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "### Query"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "zoo\nmilk = 1\nsygus\n1.0\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "### Result"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "nan\n\n\naccuracy 1.0\n\n\n\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "### Query"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "zoo\ntrue\nsygus\n1.0\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "### Result"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(and (not breathes) fins)\n\n\naccuracy 1.0\n"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from IPython.display import Markdown, display\n",
    "from trustable_explanation import helper_functions\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "features = ['hair', 'feathers', 'eggs', 'milk', 'airborne', 'aquatic', 'predator', 'toothed', 'backbone', 'breathes', 'venomous', 'fins', 'legs', 'tail', 'domestic', 'catsize']\n",
    "# print results in an explainable manner\n",
    "for key, item in df_output.groupby(['dataset','query','explainer','syntactic grammar'], as_index = False):\n",
    "    print(\"\\n\\n\")\n",
    "    display(Markdown(\"### Query\"))\n",
    "    for i in key:\n",
    "        print(i)\n",
    "    if(key[3] == 0):\n",
    "        continue\n",
    "    display(Markdown(\"### Result\"))\n",
    "    if(key[1] == \"logistic regression\"):\n",
    "        feature_importance = np.fromstring(item['explanation'].item()[1:-1], dtype=np.float, sep=' ')\n",
    "        feature_importance = 100.0 * (feature_importance / (abs(feature_importance).max()))\n",
    "        sorted_idx = np.argsort(abs(feature_importance))\n",
    "        pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "        featfig = plt.figure()\n",
    "        featax = featfig.add_subplot(1, 1, 1)\n",
    "        featax.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "        featax.set_yticks(pos)\n",
    "        featax.set_yticklabels(np.array(features)[sorted_idx])\n",
    "        featax.set_xlabel('Relative Feature Importance')\n",
    "        plt.tight_layout()   \n",
    "        plt.show()\n",
    "    elif(key[1] == \"decision tree\"):\n",
    "        dt = None\n",
    "        with open(item['explanation'].item(), 'rb') as fid:\n",
    "            dt = pickle.load(fid)\n",
    "        print(helper_functions.tree_to_code(dt,features))\n",
    "    else:\n",
    "        print(item['explanation'].item())\n",
    "    print(\"\\n\\naccuracy\",item['accuracy'].item())\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to remote \n",
    "# df_output.to_csv(\"data/output/summary.csv\", index = False)\n",
    "# df_output.to_csv(\"/home/bishwamittra/Dropbox/trustable_explanations/result.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\\begin{tabular}{llrrr}\n\\toprule\n        Query &                 Explanation & Size & Accuracy & Time \\\\\n\\midrule\n breathes = 0 &                         NaN &  0.8 &      0.9 & 0.17 \\\\\n breathes = 1 &                       false &  0.7 &      1.0 & 0.15 \\\\\n     fins = 0 &                         NaN &  0.7 &      1.0 & 0.16 \\\\\n     milk = 1 &                         NaN &  0.7 &      1.0 & 0.16 \\\\\n         true &   (and (not breathes) fins) &  2.0 &      1.0 & 0.56 \\\\\n\\bottomrule\n\\end{tabular}\n\n"
    }
   ],
   "source": [
    "def time_format(x):\n",
    "    if(x > 300):\n",
    "        return '300'\n",
    "    else:\n",
    "        return '%.2f' % x\n",
    "def dataset_format(x):\n",
    "    dic = {\n",
    "        'adult' : 'Adult',\n",
    "        'zoo' : 'Zoo',\n",
    "        'iris' : 'Iris'\n",
    "    }\n",
    "    return dic[x]\n",
    "def percentage(x):\n",
    "    return '%.2f' % x\n",
    "def single_decimal(x):\n",
    "    return '%.1f' % x\n",
    "\n",
    "def integer_format(x):\n",
    "    return '%.0f' % x\n",
    "\n",
    "if(sanity):\n",
    "    print(df_output[df_output['syntactic grammar'] == 1][['query', 'explanation', 'explanation size', 'accuracy', 'time']].to_latex(index=False, header=['Query', 'Explanation', 'Size', 'Accuracy', 'Time'], formatters={'time': time_format, 'accuracy': single_decimal, 'explanation size':single_decimal}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\\begin{tabular}{lrrrrrr}\n\\toprule\nDataset & Explanation size & Accuracy & Time & Learner(\\%) & Verifier(\\%) & Test inputs \\\\\n\\midrule\n  Adult &             4.00 &     0.69 &  300 &       0.88 &        0.12 &        4763 \\\\\n   Iris &             8.00 &     0.80 &  300 &       0.98 &        0.01 &         112 \\\\\n    Zoo &             4.00 &     0.91 &  300 &       0.96 &        0.04 &        6782 \\\\\n\\bottomrule\n\\end{tabular}\n\n"
    }
   ],
   "source": [
    "\n",
    "\n",
    "df_output['learner(%)'] = df_output['time learner']/df_output['time']\n",
    "df_output['verifier(%)'] = df_output['time verifier']/df_output['time']\n",
    "print(df_output[df_output['syntactic grammar'] == 1][['dataset', 'explanation size', 'accuracy', 'time', 'learner(%)', 'verifier(%)', 'random words checked']].to_latex(index=False, formatters=[dataset_format, , percentage, time_format, percentage, percentage, integer_format], header = ['Dataset', 'Explanation size', 'Accuracy', 'Time', 'Learner(%)', 'Verifier(%)', 'Test inputs']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "  dataset  syntactic grammar explainer  \\\n0   adult                0.0     sygus   \n1   adult                1.0     sygus   \n2    iris                0.0     sygus   \n3    iris                1.0     sygus   \n4     zoo                0.0     sygus   \n5     zoo                1.0     sygus   \n\n                                               query  \\\n0  - threshold: 0.1\\n- specific_input: [1.0, 0.24...   \n1  - threshold: 0.1\\n- specific_input: [1.0, 0.24...   \n2  - threshold: 0.1\\n- specific_input: [0.3888888...   \n3  - threshold: 0.1\\n- specific_input: [0.3888888...   \n4  - threshold: 0.1\\n- specific_input: [1.0, 0.0,...   \n5  - threshold: 0.1\\n- specific_input: [1.0, 0.0,...   \n\n                                         explanation  accuracy    time  \\\n0   (and sex race_4 (= age (/ 1232876712328767 50...      0.54    1.23   \n1   (and (not race_2) (and (not race_3) (and (< e...      0.69  301.05   \n2   (let ((_let_0 (= petal-width (/ 279 500)))) (...      0.80  302.49   \n3   (or (and (> sepal-length (/ 1 2)) (< petal-wi...      0.80  301.11   \n4   (and hair milk airborne toothed backbone brea...      1.00    0.51   \n5   (and (not feathers) (and (not eggs) (and (not...      0.91  301.04   \n\n   time learner  time verifier  random words checked  total counterexamples  \\\n0          0.20           1.02                  89.0                   17.0   \n1        264.12          35.99                4763.0                   28.5   \n2         44.02         257.67              102613.0                  132.0   \n3        296.09           4.02                 111.5                   14.0   \n4          0.25           0.27                  89.0                   17.0   \n5        288.87          11.17                6782.5                   33.5   \n\n   positive counterexamples  explanation size  learner(%)  verifier(%)  \n0                      0.06              11.0    0.162602     0.829268  \n1                      0.06               4.0    0.877329     0.119548  \n2                      0.89             604.5    0.145525     0.851830  \n3                      0.36               8.0    0.983328     0.013351  \n4                      0.06              16.0    0.490196     0.529412  \n5                      0.05               4.0    0.959573     0.037105  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>syntactic grammar</th>\n      <th>explainer</th>\n      <th>query</th>\n      <th>explanation</th>\n      <th>accuracy</th>\n      <th>time</th>\n      <th>time learner</th>\n      <th>time verifier</th>\n      <th>random words checked</th>\n      <th>total counterexamples</th>\n      <th>positive counterexamples</th>\n      <th>explanation size</th>\n      <th>learner(%)</th>\n      <th>verifier(%)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>adult</td>\n      <td>0.0</td>\n      <td>sygus</td>\n      <td>- threshold: 0.1\\n- specific_input: [1.0, 0.24...</td>\n      <td>(and sex race_4 (= age (/ 1232876712328767 50...</td>\n      <td>0.54</td>\n      <td>1.23</td>\n      <td>0.20</td>\n      <td>1.02</td>\n      <td>89.0</td>\n      <td>17.0</td>\n      <td>0.06</td>\n      <td>11.0</td>\n      <td>0.162602</td>\n      <td>0.829268</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>adult</td>\n      <td>1.0</td>\n      <td>sygus</td>\n      <td>- threshold: 0.1\\n- specific_input: [1.0, 0.24...</td>\n      <td>(and (not race_2) (and (not race_3) (and (&lt; e...</td>\n      <td>0.69</td>\n      <td>301.05</td>\n      <td>264.12</td>\n      <td>35.99</td>\n      <td>4763.0</td>\n      <td>28.5</td>\n      <td>0.06</td>\n      <td>4.0</td>\n      <td>0.877329</td>\n      <td>0.119548</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>iris</td>\n      <td>0.0</td>\n      <td>sygus</td>\n      <td>- threshold: 0.1\\n- specific_input: [0.3888888...</td>\n      <td>(let ((_let_0 (= petal-width (/ 279 500)))) (...</td>\n      <td>0.80</td>\n      <td>302.49</td>\n      <td>44.02</td>\n      <td>257.67</td>\n      <td>102613.0</td>\n      <td>132.0</td>\n      <td>0.89</td>\n      <td>604.5</td>\n      <td>0.145525</td>\n      <td>0.851830</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>iris</td>\n      <td>1.0</td>\n      <td>sygus</td>\n      <td>- threshold: 0.1\\n- specific_input: [0.3888888...</td>\n      <td>(or (and (&gt; sepal-length (/ 1 2)) (&lt; petal-wi...</td>\n      <td>0.80</td>\n      <td>301.11</td>\n      <td>296.09</td>\n      <td>4.02</td>\n      <td>111.5</td>\n      <td>14.0</td>\n      <td>0.36</td>\n      <td>8.0</td>\n      <td>0.983328</td>\n      <td>0.013351</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>zoo</td>\n      <td>0.0</td>\n      <td>sygus</td>\n      <td>- threshold: 0.1\\n- specific_input: [1.0, 0.0,...</td>\n      <td>(and hair milk airborne toothed backbone brea...</td>\n      <td>1.00</td>\n      <td>0.51</td>\n      <td>0.25</td>\n      <td>0.27</td>\n      <td>89.0</td>\n      <td>17.0</td>\n      <td>0.06</td>\n      <td>16.0</td>\n      <td>0.490196</td>\n      <td>0.529412</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>zoo</td>\n      <td>1.0</td>\n      <td>sygus</td>\n      <td>- threshold: 0.1\\n- specific_input: [1.0, 0.0,...</td>\n      <td>(and (not feathers) (and (not eggs) (and (not...</td>\n      <td>0.91</td>\n      <td>301.04</td>\n      <td>288.87</td>\n      <td>11.17</td>\n      <td>6782.5</td>\n      <td>33.5</td>\n      <td>0.05</td>\n      <td>4.0</td>\n      <td>0.959573</td>\n      <td>0.037105</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "fontsize = 22\n",
    "labelsize = 18\n",
    "df_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 288x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 288x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 288x288 with 0 Axes>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "save = True\n",
    "group_list = ['model']\n",
    "\n",
    "os.system(\"mkdir data/output/fig\")\n",
    "\n",
    "sns.set(rc={'figure.figsize':(10,8)})\n",
    "# sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
    "\n",
    "data = df_output.copy()\n",
    "data['syntactic grammar'] = data['syntactic grammar'].map({1.0: 'syn', 0.0: 'no syn'})\n",
    "data['dataset'] = data['dataset'].map({\n",
    "        'adult' : 'Adult',\n",
    "        'zoo' : 'Zoo',\n",
    "        'iris' : 'Iris'\n",
    "    })\n",
    "sns.catplot( x = 'dataset', y = 'accuracy', hue='syntactic grammar', kind=\"bar\",  height=4, data=data, palette=\"colorblind\", legend=False)\n",
    "plt.ylabel('Accuracy', fontsize=fontsize)\n",
    "plt.xlabel('Dataset', fontsize=fontsize)\n",
    "plt.xticks(fontsize=labelsize)\n",
    "plt.yticks(fontsize=labelsize)\n",
    "plt.legend(loc='best', fontsize=labelsize-4, frameon=False)\n",
    "# plt.yscale('log')\n",
    "plt.tight_layout()\n",
    "\n",
    "if(save):\n",
    "    plt.savefig(\"data/output/fig/accuracy.pdf\")\n",
    "    pass\n",
    "else:\n",
    "    plt.show()\n",
    "plt.clf()\n",
    "\n",
    "\n",
    "sns.catplot( x = 'dataset', y = 'time', hue='syntactic grammar', kind=\"bar\",  height=4, data=data, palette=\"colorblind\", legend=False)\n",
    "plt.ylabel('Time', fontsize=fontsize)\n",
    "plt.xlabel('Dataset', fontsize=fontsize)\n",
    "plt.xticks(fontsize=labelsize)\n",
    "plt.yticks(fontsize=labelsize)\n",
    "plt.legend(loc='best', fontsize=labelsize-4, frameon=False)\n",
    "plt.yscale('log')\n",
    "plt.tight_layout()\n",
    "\n",
    "if(save):\n",
    "    plt.savefig(\"data/output/fig/time.pdf\")\n",
    "    pass\n",
    "else:\n",
    "    plt.show()\n",
    "plt.clf()\n",
    "\n",
    "sns.catplot( x = 'dataset', y = 'explanation size', hue='syntactic grammar', kind=\"bar\",  height=4, data=data, palette=\"colorblind\", legend=False)\n",
    "plt.ylabel('Explanation size', fontsize=fontsize)\n",
    "plt.xlabel('Dataset', fontsize=fontsize)\n",
    "plt.xticks(fontsize=labelsize)\n",
    "plt.yticks(fontsize=labelsize)\n",
    "plt.legend(loc='best', fontsize=labelsize-4, frameon=False)\n",
    "plt.yscale('log')\n",
    "plt.tight_layout()\n",
    "\n",
    "if(save):\n",
    "    plt.savefig(\"data/output/fig/size.pdf\")\n",
    "    pass\n",
    "else:\n",
    "    plt.show()\n",
    "plt.clf()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}