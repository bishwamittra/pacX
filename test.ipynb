{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'legs': (1.0, 0.0)}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lark import Lark\n",
    "import time \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import metrics\n",
    "from IPython.display import Markdown, display\n",
    "import pickle\n",
    "import os.path\n",
    "from pac_explanation import utils\n",
    "from  pac_explanation.query import Query\n",
    "import operator\n",
    "from pac_explanation import example_queries\n",
    "from pac_explanation.teacher import Teacher\n",
    "from pac_explanation.learner import Learner\n",
    "from pac_explanation.sygus_if import SyGuS_IF\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from pac_explanation.blackbox import BlackBox\n",
    "import matplotlib.pyplot as plt\n",
    "from data.objects import zoo, iris, adult\n",
    "from pac_explanation.example_queries import DistanceQuery\n",
    "import datetime\n",
    "\n",
    "\n",
    "select_blackbox = ['decision tree','neural network', 'random forest'][0]\n",
    "\n",
    "dataset = ['zoo', 'adult', 'iris'][0]\n",
    "\n",
    "df = None\n",
    "\n",
    "if(dataset == \"zoo\"):\n",
    "    dataObj = zoo.Zoo()\n",
    "    df = dataObj.get_df()\n",
    "    # fix target class\n",
    "    target_class = [4] \n",
    "    _temp = {}\n",
    "    for i in range(1, len(df[dataObj.target].unique())+1):\n",
    "        if(i in target_class):\n",
    "            _temp[i] = 1\n",
    "        else:\n",
    "            _temp[i] = 0\n",
    "    df[dataObj.target] = df[dataObj.target].map(_temp)\n",
    "elif(dataset == \"adult\"):\n",
    "    dataObj = adult.Adult() \n",
    "    df = dataObj.get_df()\n",
    "elif(dataset == \"iris\"):\n",
    "    dataObj = iris.Iris()\n",
    "    df = dataObj.get_df()\n",
    "\n",
    "\n",
    "\n",
    "print(dataObj.real_attribute_domain_info)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "# Train the blackbox"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loding model\ndef tree(hair, feathers, eggs, milk, airborne, aquatic, predator, toothed, backbone, breathes, venomous, fins, legs, tail, domestic, catsize):\n\n    if fins <= 0.5:\n        return 0\n    else:\n        if breathes <= 0.5:\n            return 1\n        else:\n            return 0\n\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "### Query"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Query is a logical specification\n\nCalling SyGuS learner\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "### Result for sygus"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Learned explanation =>  (or (not aquatic) (or domestic (< legs (/ 2 5))))\n-explanation size: 3\n\n\n\n-is learning complete? False\n-it took 11.007745027542114 seconds\n-learner time: 9.769218921661377\n-verifier time: 0.23346734046936035\ncorrect:  2 out of  11 examples. Percentage:  0.18181818181818182\nrandom words checked 123\nFiltered by querys: 0\nTotal counterexamples: 8\npercentage of positive counterexamples for the learner: 0.375\n\n'accuracy', 'blackbox', 'dataset', 'explainer', 'explanation', 'explanation size', 'positive counterexamples', 'query', 'random words checked', 'syntactic grammar', 'terminate', 'time', 'time learner', 'time verifier', 'total counterexamples'\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "### Query"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Query is a logical specification\nfins = 1\nCalling SyGuS learner\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "### Result for sygus"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Learned explanation =>  (not breathes)\n-explanation size: 0\n\n\n\n-is learning complete? True\n-it took 0.26505613327026367 seconds\n-learner time: 0.16980576515197754\n-verifier time: 0.09300470352172852\ncorrect:  11 out of  11 examples. Percentage:  1.0\nrandom words checked 98\nFiltered by querys: 46\nTotal counterexamples: 4\npercentage of positive counterexamples for the learner: 0.5\n\n'accuracy', 'blackbox', 'dataset', 'explainer', 'explanation', 'explanation size', 'positive counterexamples', 'query', 'random words checked', 'syntactic grammar', 'terminate', 'time', 'time learner', 'time verifier', 'total counterexamples'\n"
     ]
    }
   ],
   "source": [
    "# declaration of classifier, X and y\n",
    "X = df.drop([dataObj.target], axis=1)\n",
    "y = df[dataObj.target]\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, shuffle = True, random_state=2) # 70% training and 30% test\n",
    "\n",
    "display(Markdown(\"# Train the blackbox\"))\n",
    "\n",
    "model_name = None\n",
    "if(select_blackbox == 'decision tree'):\n",
    "    model_name = 'data/model/dt_' + dataset + '.pkl'\n",
    "elif(select_blackbox == \"random forest\"):\n",
    "    model_name = 'data/model/rf_' + dataset + '.pkl'\n",
    "elif(select_blackbox == \"neural network\"):\n",
    "    model_name = 'data/model/nn_' + dataset + '.pkl'\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"Black box not defined\")\n",
    "\n",
    "\n",
    "\n",
    "if(not os.path.isfile(model_name)):\n",
    "    clf = None\n",
    "    if(select_blackbox == 'decision tree'):\n",
    "        param_grid = {'max_depth': np.arange(3, 10)}\n",
    "        grid_tree = GridSearchCV(tree.DecisionTreeClassifier(random_state=0), param_grid)\n",
    "        grid_tree.fit(X_train, y_train)\n",
    "        tree_preds = grid_tree.predict_proba(X_test)[:, 1]\n",
    "        tree_performance = roc_auc_score(y_test, tree_preds)\n",
    "        clf = grid_tree.best_estimator_\n",
    "        print(utils.tree_to_code(clf,X_train.columns.tolist()))\n",
    "    elif(select_blackbox == \"random forest\"):\n",
    "        clf = RandomForestClassifier(n_estimators=100)\n",
    "        clf.fit(X_train,y_train)\n",
    "\n",
    "    elif(select_blackbox == \"neural network\"):\n",
    "        clf = MLPClassifier(random_state=1, max_iter=300).fit(X_train, y_train) \n",
    "        clf.fit(X_train,y_train)\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(\"Black box not defined\")\n",
    "\n",
    "    \n",
    "\n",
    "    # save the classifier\n",
    "    with open(model_name, 'wb') as fid:\n",
    "        pickle.dump(clf, fid)    \n",
    "\n",
    "else:\n",
    "    print(\"Loding model\")\n",
    "    with open(model_name, 'rb') as fid:\n",
    "        clf = pickle.load(fid)\n",
    "    \n",
    "    if(select_blackbox == \"decision tree\"):\n",
    "        print(utils.tree_to_code(clf,X_train.columns.tolist()))\n",
    "\n",
    "\n",
    "\n",
    "# os.system(\"rm \" + model_name)\n",
    "\n",
    "\n",
    "\n",
    "# our query is a halfspace and conjunction of the following\n",
    "queries = [\n",
    "    \n",
    "    {\n",
    "     \n",
    "    },    \n",
    "    {\n",
    "        'fins' : (operator.eq, 1)\n",
    "    },\n",
    "    # {\n",
    "    #     'breathes' : (operator.eq, 0)\n",
    "    # },\n",
    "    # {\n",
    "    #     'breathes' : (operator.eq, 1)\n",
    "    # },\n",
    "    # {\n",
    "    #     'milk' : (operator.eq, 1)\n",
    "    # },\n",
    "    \n",
    "\n",
    "]\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "bb = None\n",
    "if(select_blackbox == 'decision tree'):\n",
    "    bb = BlackBox(clf, clf.predict)\n",
    "elif(select_blackbox == \"random forest\"):\n",
    "    bb = BlackBox(clf, clf.predict)\n",
    "elif(select_blackbox == \"neural network\"):\n",
    "    bb = BlackBox(clf, clf.predict)\n",
    "else:\n",
    "    raise ValueError(\"Black box not defined\")\n",
    "\n",
    "\n",
    "select_query = ['decision tree', 'specific input'][0]\n",
    "\n",
    "for selected_learner  in [\"decision tree\", \"logistic regression\", \"sygus\"][2:]:\n",
    "    for _query in queries:\n",
    "            \n",
    "        query_class = None\n",
    "        X = y = None\n",
    "        if(select_query == \"decision tree\"):\n",
    "            # We define query specilized for decision tree\n",
    "            query_class = example_queries.DecisionTree(features=X_train.columns.tolist(), halfspace=_query)\n",
    "            X = []\n",
    "            y = []\n",
    "        elif(select_query == \"specific input\"):        \n",
    "            specific_input = X_train.iloc[0].tolist()\n",
    "            query_class = example_queries.DistanceQuery(specific_input=specific_input, threshold=0.5, features = X_train.columns.tolist())\n",
    "            X = [specific_input]\n",
    "            y = [clf.predict([specific_input])[0]]\n",
    "            print(\"Class (black-box)\", y)\n",
    "            \n",
    "        else:\n",
    "\n",
    "            raise ValueError(select_query +\" is not a defined query.\")\n",
    "        \n",
    "        display(Markdown(\"### Query\"))\n",
    "        q = Query(model = None, prediction_function = query_class.predict_function_query)\n",
    "        print(query_class)\n",
    "\n",
    "        iterations = 1\n",
    "\n",
    "        for syntactic_grammar in [True]:\n",
    "            \n",
    "            for idx in range(iterations):\n",
    "\n",
    "                if(selected_learner == \"sygus\"):\n",
    "                    print(\"Calling SyGuS learner\")\n",
    "                    sgf = SyGuS_IF(rule_type=\"DNF\", k = 1, feature_names=dataObj.attributes, feature_data_type=dataObj.attribute_type, function_return_type= \"Bool\", verbose=False, syntactic_grammar = syntactic_grammar )\n",
    "                    l = Learner(model = sgf, prediction_function = sgf.predict_z3, train_function = sgf.fit, X = X, y=y)\n",
    "                elif(selected_learner == \"decision tree\"):\n",
    "                    dt_classifier = tree.DecisionTreeClassifier()\n",
    "                    l = Learner(model = dt_classifier, prediction_function = dt_classifier.predict, train_function = dt_classifier.fit, X = X, y=y )\n",
    "                elif(selected_learner == \"logistic regression\"):\n",
    "                    clf_lr = LogisticRegression()\n",
    "                    l = Learner(model = clf_lr, prediction_function = clf_lr.predict, train_function = clf_lr.fit, X = X, y=y )\n",
    "\n",
    "                else:\n",
    "                    raise ValueError(\"Learner not defined\")\n",
    "\n",
    "                \n",
    "                t = Teacher(max_iterations=100000,epsilon=0.051, delta=0.501, timeout=10)\n",
    "                _teach_start = time.time()\n",
    "                l, flag = t.teach(blackbox = bb, learner = l, query = q, random_example_generator = utils.random_generator, params_generator = (X_train,dataObj.attribute_type), verbose=False)\n",
    "\n",
    "                _teach_end = time.time()\n",
    "\n",
    "\n",
    "                \n",
    "\n",
    "\n",
    "                acc = None\n",
    "\n",
    "                try:\n",
    "                    cnt = 0\n",
    "                    learner_verdicts = l.classify_examples(X_test.values.tolist())\n",
    "                    blackbox_verdicts = bb.classify_examples(X_test.values.tolist())\n",
    "                    for i in range(len(X_test.values.tolist())):\n",
    "\n",
    "                        blackbox_verdict = blackbox_verdicts[i]\n",
    "                        learner_verdict = learner_verdicts[i]\n",
    "                        query_verdict = q.classify_example(X_test.values.tolist()[i])\n",
    "                        if(not query_verdict):\n",
    "                            cnt += 1\n",
    "                            continue\n",
    "                        if(learner_verdict == blackbox_verdict):\n",
    "                            cnt += 1\n",
    "                    acc = cnt/len(y_test)\n",
    "                except:\n",
    "                    cnt = None\n",
    "                    acc = None\n",
    "\n",
    "                \n",
    "\n",
    "                # result\n",
    "                entry = {}\n",
    "                entry['dataset'] = dataset\n",
    "                entry['blackbox'] = select_blackbox\n",
    "                entry['query'] = str(query_class)\n",
    "                if(selected_learner == \"sygus\"):\n",
    "                    entry['explanation'] = l.model._function_snippet\n",
    "                    entry['explanation size'] = l.model.get_formula_size()\n",
    "                elif(selected_learner == \"decision tree\"):\n",
    "                    os.system(\"mkdir -p data/output/dt\")\n",
    "                    _dt_explanation_file = \"data/output/dt/\" + str(datetime.datetime.now()) + \".pkl\"\n",
    "                    with open(_dt_explanation_file, 'wb') as fid:\n",
    "                        pickle.dump(l.model, fid)\n",
    "                    entry['explanation'] = _dt_explanation_file\n",
    "                    entry['explanation size'] = None\n",
    "                elif(selected_learner == \"logistic regression\"):\n",
    "                    entry['explanation'] = l.model.coef_[0]\n",
    "                    entry['explanation size'] = None\n",
    "                else:\n",
    "                    raise ValueError\n",
    "                entry['explainer'] = selected_learner\n",
    "                entry['syntactic grammar'] = syntactic_grammar\n",
    "                entry['time learner'] = t.time_learner\n",
    "                entry['time verifier'] = t.time_verifier\n",
    "                entry['time'] = _teach_end - _teach_start\n",
    "                entry['accuracy'] = acc\n",
    "                entry['terminate'] = flag\n",
    "                entry['random words checked'] = t.verifier.number_of_examples_checked\n",
    "                entry['total counterexamples'] = len(l.y)\n",
    "                entry['positive counterexamples'] = np.array(l.y).mean()\n",
    "\n",
    "                \n",
    "                result = pd.DataFrame()\n",
    "                result = result.append(entry, ignore_index=True)\n",
    "                result.to_csv('data/output/sanity_result.csv', header=False, index=False, mode='a')\n",
    "\n",
    "\n",
    "                if(idx == iterations - 1):\n",
    "                    display(Markdown(\"### Result for \" + selected_learner))\n",
    "                    if(selected_learner == \"sygus\"):\n",
    "                        print(\"Learned explanation =>\", l.model._function_snippet)\n",
    "                        print(\"-explanation size:\", l.model.get_formula_size())\n",
    "                    elif(selected_learner == \"decision tree\"):\n",
    "                        print(\"Learned explanation =>\", utils.tree_to_code(l.model,X_train.columns.to_list()), \"\\n\\n\")\n",
    "                    elif(selected_learner == \"logistic regression\"):\n",
    "                        feature_importance = l.model.coef_[0]\n",
    "                        feature_importance = 100.0 * (feature_importance / (abs(feature_importance).max()))\n",
    "                        sorted_idx = np.argsort(abs(feature_importance))\n",
    "                        pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "                        featfig = plt.figure()\n",
    "                        featax = featfig.add_subplot(1, 1, 1)\n",
    "                        featax.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "                        featax.set_yticks(pos)\n",
    "                        featax.set_yticklabels(np.array(X_train.columns.to_list())[sorted_idx])\n",
    "                        featax.set_xlabel('Relative Feature Importance')\n",
    "                        plt.tight_layout()   \n",
    "                        plt.show()\n",
    "                    else:\n",
    "                        raise ValueError\n",
    "\n",
    "\n",
    "                    print(\"\\n\\n\\n-is learning complete?\", flag)\n",
    "                    print(\"-it took\", _teach_end - _teach_start, \"seconds\")\n",
    "                    print(\"-learner time:\", t.time_learner)\n",
    "                    print(\"-verifier time:\", t.time_verifier)\n",
    "                    print(\"correct: \", cnt, \"out of \", len(y_test), \"examples. Percentage: \", acc)\n",
    "                    print('random words checked', t.verifier.number_of_examples_checked)\n",
    "                    print(\"Filtered by querys:\", t.verifier.filtered_by_query)\n",
    "                    print(\"Total counterexamples:\", len(l.y))\n",
    "                    print(\"percentage of positive counterexamples for the learner:\", np.array(l.y).mean())\n",
    "                    print()\n",
    "                    print(\", \".join([\"\\'\" + column + \"\\'\" for column in result.columns.tolist()]))\n",
    "\n",
    "        if(select_query == \"specific input\"):\n",
    "            break\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "source": [
    "### Query details\n",
    "Query should be self-sufficient. In the distance-based query, the distance threshold should be generated automatically"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}