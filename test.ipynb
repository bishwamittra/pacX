{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lark import Lark\n",
    "import time \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import metrics\n",
    "from IPython.display import Markdown, display\n",
    "import pickle\n",
    "import os.path\n",
    "sys.path.append(\"trustable_explanation/\")\n",
    "sys.path.append(\"trustable_explanation/\")\n",
    "import helper_functions\n",
    "import query\n",
    "import operator\n",
    "from blackbox_dt import DecisionTree\n",
    "from teacher import Teacher\n",
    "from learner import Learner\n",
    "from sygus_if import SyGuS_IF\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from blackbox import BlackBox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "-number of samples: (before dropping nan rows) 101\n-number of samples: (after dropping nan rows) 101\n{1: 1, 2: 1, 3: 1, 4: 0, 5: 0, 6: 0, 7: 0}\n   hair  feathers  eggs  milk  airborne  aquatic  predator  toothed  backbone  \\\n0     1         0     0     1         0        0         1        1         1   \n1     1         0     0     1         0        0         0        1         1   \n2     0         0     1     0         0        1         1        1         1   \n3     1         0     0     1         0        0         1        1         1   \n4     1         0     0     1         0        0         1        1         1   \n\n   breathes  venomous  fins  legs  tail  domestic  catsize  class_type  \n0         1         0     0   0.5     0         0        1           1  \n1         1         0     0   0.5     1         0        1           1  \n2         0         0     1   0.0     1         0        0           0  \n3         1         0     0   0.5     0         0        1           1  \n4         1         0     0   0.5     1         0        1           1  \n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "# Train the blackbox"
     },
     "metadata": {}
    }
   ],
   "source": [
    "from data.objects import zoo\n",
    "\n",
    "dataObj = zoo.Zoo()\n",
    "df = dataObj.get_df()\n",
    "\n",
    "# fix target class\n",
    "target_class = [1,2,3] \n",
    "_temp = {}\n",
    "for i in range(1, len(df[dataObj.target].unique())+1):\n",
    "    if(i in target_class):\n",
    "        _temp[i] = 1\n",
    "    else:\n",
    "        _temp[i] = 0\n",
    "print(_temp)\n",
    "df[dataObj.target] = df[dataObj.target].map(_temp)\n",
    "\n",
    "\n",
    "# declaration of classifier, X and y\n",
    "X = df.drop([dataObj.target], axis=1)\n",
    "y = df[dataObj.target]\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=2) # 70% training and 30% test\n",
    "\n",
    "\n",
    "print(df.head())\n",
    "display(Markdown(\"# Train the blackbox\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Loding model\nAccuracy decision tree: 1.0\nAccuracy random forest: 1.0\nAccuracy neural netwrk: 1.0\ndef tree(hair, feathers, eggs, milk, airborne, aquatic, predator, toothed, backbone, breathes, venomous, fins, legs, tail, domestic, catsize):\n\n    if breathes <= 0.5:\n        if eggs <= 0.5:\n            return 1\n        else:\n            return 0\n    else:\n        if backbone <= 0.5:\n            return 0\n        else:\n            if aquatic <= 0.5:\n                return 1\n            else:\n                if legs <= 0.375:\n                    return 1\n                else:\n                    if milk <= 0.5:\n                        return 0\n                    else:\n                        return 1\n\n"
    }
   ],
   "source": [
    "\n",
    "model_name = 'data/model/dt_zoo.pkl'\n",
    "\n",
    "clf_rf=RandomForestClassifier(n_estimators=100)\n",
    "clf_mlp = MLPClassifier(random_state=1, max_iter=300).fit(X_train, y_train)\n",
    "\n",
    "clf_rf.fit(X_train,y_train)\n",
    "clf_mlp.fit(X_train,y_train)\n",
    "\n",
    "if(not os.path.isfile(model_name)):\n",
    "    param_grid = {'max_depth': np.arange(3, 10)}\n",
    "    grid_tree = GridSearchCV(tree.DecisionTreeClassifier(random_state=0), param_grid)\n",
    "    grid_tree.fit(X_train, y_train)\n",
    "    tree_preds = grid_tree.predict_proba(X_test)[:, 1]\n",
    "    tree_performance = roc_auc_score(y_test, tree_preds)\n",
    "    clf_dt = grid_tree.best_estimator_\n",
    "\n",
    "    # save the classifier\n",
    "    with open(model_name, 'wb') as fid:\n",
    "        pickle.dump(clf_dt, fid)    \n",
    "\n",
    "else:\n",
    "    print(\"Loding model\")\n",
    "    with open('data/model/dt_zoo.pkl', 'rb') as fid:\n",
    "        clf_dt = pickle.load(fid)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Accuracy decision tree:\",metrics.accuracy_score(y_test, clf_dt.predict(X_test)))\n",
    "print(\"Accuracy random forest:\",metrics.accuracy_score(y_test, clf_rf.predict(X_test)))\n",
    "print(\"Accuracy neural netwrk:\",metrics.accuracy_score(y_test, clf_mlp.predict(X_test)))\n",
    "print(helper_functions.tree_to_code(clf_dt, X_train.columns.to_list()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# our query is a halfspace and conjunction of the following\n",
    "queries = [\n",
    "    \n",
    "    {\n",
    "        \"breathes\" : (operator.eq, 0)\n",
    "    },\n",
    "\n",
    "    {\n",
    "        'eggs' : (operator.eq, 0)\n",
    "    },\n",
    "\n",
    "    {\n",
    "        'backbone' : (operator.eq, 1)\n",
    "    },\n",
    "\n",
    "    {\n",
    "        'legs' : (operator.le, 0.2)\n",
    "    },\n",
    "\n",
    "    {\n",
    "        'legs' : (operator.ge, 0.4),\n",
    "        'milk' : (operator.eq, 1)\n",
    "    },\n",
    "\n",
    "    {\n",
    "        'aquatic' : (operator.eq, 0)\n",
    "    }\n",
    "\n",
    "\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "### Query"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "breathes = 0\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "### Result"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Learned explanation =>  (not (or eggs breathes))\nbreathes = 0\n-is learning complete? True\n-it took 3.0234665870666504 seconds\ncorrect:  11 out of  11 examples. Percentage:  1.0\nTotal counterexamples checked: 349\npercentage of positive examples for the learner: 0.4\n\n'accuracy', 'counterexamples checked', 'explanation', 'positive counterexamples', 'query', 'terminate', 'time', 'time learner', 'time verifier'\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "### Query"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "eggs = 0\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "### Result"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Learned explanation =>  (not (and breathes (or (and hair airborne) (and aquatic domestic))))\neggs = 0\n-is learning complete? False\n-it took 61.00668740272522 seconds\ncorrect:  1 out of  11 examples. Percentage:  0.09090909090909091\nTotal counterexamples checked: 160\npercentage of positive examples for the learner: 0.4666666666666667\n\n'accuracy', 'counterexamples checked', 'explanation', 'positive counterexamples', 'query', 'terminate', 'time', 'time learner', 'time verifier'\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "### Query"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "backbone = 1\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "### Result"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Learned explanation =>  (and backbone (or milk (or airborne (and feathers (or toothed fins)))))\nbackbone = 1\n-is learning complete? False\n-it took 61.012935400009155 seconds\ncorrect:  11 out of  11 examples. Percentage:  1.0\nTotal counterexamples checked: 259\npercentage of positive examples for the learner: 0.42857142857142855\n\n'accuracy', 'counterexamples checked', 'explanation', 'positive counterexamples', 'query', 'terminate', 'time', 'time learner', 'time verifier'\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "### Query"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "legs <= 0.2\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "### Result"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Learned explanation =>  (and (or hair domestic) (or aquatic (not (or eggs predator))))\nlegs <= 0.2\n-is learning complete? False\n-it took 61.03347206115723 seconds\ncorrect:  9 out of  11 examples. Percentage:  0.8181818181818182\nTotal counterexamples checked: 234\npercentage of positive examples for the learner: 0.5\n\n'accuracy', 'counterexamples checked', 'explanation', 'positive counterexamples', 'query', 'terminate', 'time', 'time learner', 'time verifier'\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "### Query"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "legs >= 0.4 And milk = 1\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "### Result"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Learned explanation =>  (and milk (or aquatic (or domestic (not feathers))))\nlegs >= 0.4 And milk = 1\n-is learning complete? False\n-it took 61.0459258556366 seconds\ncorrect:  10 out of  11 examples. Percentage:  0.9090909090909091\nTotal counterexamples checked: 177\npercentage of positive examples for the learner: 0.5\n\n'accuracy', 'counterexamples checked', 'explanation', 'positive counterexamples', 'query', 'terminate', 'time', 'time learner', 'time verifier'\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "### Query"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "aquatic = 0\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "### Result"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Learned explanation =>  (not (or aquatic (and (not backbone) (or eggs breathes))))\naquatic = 0\n-is learning complete? False\n-it took 61.012948513031006 seconds\ncorrect:  11 out of  11 examples. Percentage:  1.0\nTotal counterexamples checked: 398\npercentage of positive examples for the learner: 0.42857142857142855\n\n'accuracy', 'counterexamples checked', 'explanation', 'positive counterexamples', 'query', 'terminate', 'time', 'time learner', 'time verifier'\n"
    }
   ],
   "source": [
    "bb = BlackBox(clf_dt, clf_dt.predict)\n",
    "\n",
    "for _query in queries:\n",
    "    # We define query specilized for decision tree\n",
    "    bb_dt = DecisionTree(features=X_train.columns.tolist(), halfspace=_query)\n",
    "    display(Markdown(\"### Query\"))\n",
    "    print(bb_dt)\n",
    "\n",
    "    q = query.Query(model = None, prediction_function = bb_dt.predict_function_query)\n",
    "\n",
    "\n",
    "    iterations = 4\n",
    "\n",
    "    for idx in range(iterations):\n",
    "\n",
    "        sgf = SyGuS_IF(feature_names=dataObj.attributes, feature_data_type=dataObj.attribute_type, function_return_type= \"Bool\")\n",
    "        l = Learner(model = sgf, prediction_function = sgf.predict_z3, train_function = sgf.fit, X = [], y=[] )\n",
    "\n",
    "        # dt_classifier = tree.DecisionTreeClassifier()\n",
    "        # l = Learner(model = dt_classifier, prediction_function = dt_classifier.predict, train_function = dt_classifier.fit, X = [], y=[] )\n",
    "\n",
    "\n",
    "        t = Teacher(max_iterations=1000,epsilon=0.05, delta=0.05, timeout=60)\n",
    "        _teach_start = time.time()\n",
    "        l, flag = t.teach(blackbox = bb, learner = l, query = q, random_example_generator = helper_functions.random_generator, params_generator = (X_train,dataObj.attribute_type), verbose=False)\n",
    "\n",
    "        _teach_end = time.time()\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        start_ = time.time()\n",
    "        cnt = 0\n",
    "        for example in X_test.values.tolist():\n",
    "\n",
    "            blackbox_verdict = bb.classify_example(example)\n",
    "            learner_verdict = l.classify_example(example)\n",
    "            query_verdict = q.classify_example(example)\n",
    "\n",
    "            if(learner_verdict == (blackbox_verdict and query_verdict)):\n",
    "                cnt += 1\n",
    "\n",
    "\n",
    "\n",
    "        # result\n",
    "        entry = {}\n",
    "        entry['query'] = str(bb_dt)\n",
    "        entry['explanation'] = l.model._function_snippet\n",
    "        entry['time learner'] = t.time_learner\n",
    "        entry['time verifier'] = t.time_verifier\n",
    "        entry['time'] = _teach_end - _teach_start\n",
    "        entry['accuracy'] = cnt/len(y_test)\n",
    "        entry['terminate'] = flag\n",
    "        entry['counterexamples checked'] = t.verifier.number_of_examples_checked\n",
    "        entry['positive counterexamples'] = np.array(l.y).mean()\n",
    "\n",
    "\n",
    "        result = pd.DataFrame()\n",
    "        result = result.append(entry, ignore_index=True)\n",
    "        result.to_csv('data/output/result.csv', header=False, index=False, mode='a')\n",
    "\n",
    "\n",
    "        if(idx == iterations - 1):\n",
    "            display(Markdown(\"### Result\"))\n",
    "            print(\"Learned explanation =>\", l.model._function_snippet)\n",
    "            print(str(bb_dt))\n",
    "            # print(\"Learned explanation =>\", tree_to_code(l.model,X_train.columns.to_list()), \"\\n\\n\")\n",
    "            print(\"-is learning complete?\", flag)\n",
    "            print(\"-it took\", _teach_end - _teach_start, \"seconds\")\n",
    "            print(\"correct: \", cnt, \"out of \", len(y_test), \"examples. Percentage: \", cnt/len(y_test))\n",
    "            print(\"Total counterexamples checked:\", t.verifier.number_of_examples_checked)\n",
    "            print(\"percentage of positive examples for the learner:\", np.array(l.y).mean())\n",
    "            print()\n",
    "            print(\", \".join([\"\\'\" + column + \"\\'\" for column in result.columns.tolist()]))\n",
    "\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning on Zoo dataset using SyGus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "-number of samples: (before dropping nan rows) 101\n-number of samples: (after dropping nan rows) 101\n milk\nAccuracy: 1.0\n1.179483413696289\nAccuracy: 1.0\n1.5457830429077148\n"
    }
   ],
   "source": [
    "from data.objects import zoo\n",
    "from sygus_if import SyGuS_IF\n",
    "\n",
    "dataObj = zoo.Zoo()\n",
    "df = dataObj.get_df()\n",
    "\n",
    "# fix target class\n",
    "target_class = 1 \n",
    "_temp = {}\n",
    "for i in range(1, len(df[dataObj.target].unique())+1):\n",
    "    if(i == target_class):\n",
    "        _temp[i] = 1\n",
    "    else:\n",
    "        _temp[i] = 0\n",
    "df[dataObj.target] = df[dataObj.target].map(_temp)\n",
    "\n",
    "# declaration of classifier, X and y\n",
    "sgf = SyGuS_IF(feature_names=dataObj.attributes, feature_data_type=dataObj.attribute_type, function_return_type= \"Bool\")\n",
    "X = df.drop([dataObj.target], axis=1)\n",
    "y = df[dataObj.target].tolist()\n",
    "\n",
    "# train\n",
    "sgf.fit(X,y)\n",
    "print(sgf._function_snippet)\n",
    "\n",
    "\n",
    "start_ = time.time()\n",
    "y_pred_test = sgf.predict_z3(X)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y, y_pred_test))\n",
    "print(time.time() - start_)\n",
    "\n",
    "\n",
    "start_ = time.time()\n",
    "y_pred_test = sgf.predict(X, y)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y, y_pred_test))\n",
    "print(time.time() - start_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}